,model,data,Macro F1 (vanilla),Accuracy (vanilla),Macro F1 (add v2),Accuracy (add v2),Macro F1 (add v3),Accuracy (add v3),Macro F1 Gain (v2),Accuracy Gain (v2),Macro F1 Gain (v3),Accuracy Gain (v3)
0,albert-base-v2,amcd,91.0900347314988,96.40179910044976,91.09639910989553,96.47676161919041,91.5398274987316,96.7016491754123,0.006364378396725101,0.07496251874064797,0.44979276723279327,0.299850074962535
1,albert-base-v2,chemprot,48.8380592239384,76.6503315076391,52.095503740906246,78.6105505909484,51.80474952729155,78.00518881522052,3.257444516967844,1.9602190833093118,2.966690303353147,1.354857307581426
2,albert-base-v2,citation-intent,35.302705917335715,69.7841726618705,68.96413110698826,78.41726618705036,71.24214792299898,78.41726618705036,33.66142518965255,8.63309352517986,35.93944200566327,8.63309352517986
3,albert-base-v2,rct-sample,58.67537067829206,75.46706487473038,72.65870460412643,78.56313257010122,71.93386947630881,78.49012775842044,13.983333925834366,3.0960676953708344,13.258498798016753,3.0230628836900593
4,albert-base-v2,sciie,72.92022090081885,83.47022587268994,70.55061918702529,80.59548254620124,75.14230166649308,84.49691991786447,-2.369601713793557,-2.874743326488698,2.222080765674235,1.026694045174537
5,albert-base-v2,tweet-eval-emotion,70.91106158990983,75.15833919774806,73.12649091702177,76.28430682617875,73.8059065532257,77.19915552427867,2.2154293271119343,1.1259676284306863,2.8948449633158617,2.040816326530603
6,albert-base-v2,tweet-eval-hate,51.089799476896246,54.20875420875421,50.16350470341806,53.36700336700336,52.10326389066336,54.94949494949495,-0.9262947734781832,-0.8417508417508444,1.0134644137671103,0.7407407407407405
7,albert-base-v2,tweet-eval-irony,69.95948395351317,70.66326530612244,64.9770069636053,65.3061224489796,70.0182270584905,70.53571428571429,-4.982476989907866,-5.357142857142847,0.05874310497732438,-0.12755102040814847
8,albert-base-v2,yelp-review,58.16805672756639,58.099999999999994,57.85305545336915,57.75,57.13665986578403,57.25,-0.3150012741972361,-0.3499999999999943,-1.0313968617823548,-0.8499999999999943
9,roberta-base,amcd,90.35478911417998,96.02698650674662,91.55789126128109,96.55172413793103,91.87904346045504,96.7016491754123,1.2031021471011059,0.5247376311844079,1.5242543462750575,0.6746626686656754
10,roberta-base,chemprot,55.183239782393464,80.74373018160853,53.629015359860546,80.28250216200634,55.18544406235223,82.18506774286539,-1.5542244225329185,-0.4612280196021885,0.0022042799587680406,1.4413375612568586
11,roberta-base,citation-intent,56.756662368364495,75.53956834532374,67.81470579990469,79.13669064748201,64.42399568848688,76.2589928057554,11.058043431540192,3.597122302158269,7.667333320122388,0.7194244604316538
12,roberta-base,rct-sample,73.33113365650325,80.01327360212377,72.86768763678178,80.03982080637132,72.79489568912886,80.059731209557,-0.4634460197214736,0.026547204247549416,-0.5362379673743902,0.04645760743322569
13,roberta-base,sciie,73.83315646502606,83.67556468172485,80.56148897265113,86.24229979466119,81.35734418101636,87.47433264887063,6.728332507625069,2.5667351129363425,7.524187715990294,3.7987679671457784
14,roberta-base,tweet-eval-emotion,78.94282683392085,81.63265306122449,76.92674956555565,80.85855031667839,78.68502171564637,81.77339901477832,-2.016077268365194,-0.7741027445460986,-0.25780511827447583,0.14074595355383224
15,roberta-base,tweet-eval-hate,46.393085827839634,51.44781144781144,48.001644994166526,52.52525252525253,48.4597165210036,52.861952861952865,1.6085591663268914,1.0774410774410939,2.0666306931639653,1.414141414141426
16,roberta-base,tweet-eval-irony,69.23845193508114,70.53571428571429,76.34201221472195,76.53061224489795,73.69278237455703,73.85204081632652,7.103560279640803,5.99489795918366,4.454330439475882,3.31632653061223
17,roberta-base,yelp-review,58.810540402868824,58.75,58.823739032781134,58.85,58.020187283403615,57.85,0.013198629912309912,0.10000000000000142,-0.7903531194652089,-0.8999999999999986
